{"ast":null,"code":"// TODO:\n//  * support 1 nested multipart level\n//    (see second multipart example here:\n//     http://www.w3.org/TR/html401/interact/forms.html#didx-multipartform-data)\n//  * support limits.fieldNameSize\n//     -- this will require modifications to utils.parseParams\nvar ReadableStream = require('stream').Readable || require('readable-stream'),\n    inherits = require('util').inherits;\n\nvar Dicer = require('dicer');\n\nvar parseParams = require('../utils').parseParams,\n    decodeText = require('../utils').decodeText,\n    basename = require('../utils').basename;\n\nvar RE_BOUNDARY = /^boundary$/i,\n    RE_FIELD = /^form-data$/i,\n    RE_CHARSET = /^charset$/i,\n    RE_FILENAME = /^filename$/i,\n    RE_NAME = /^name$/i;\nMultipart.detect = /^multipart\\/form-data/i;\n\nfunction Multipart(boy, cfg) {\n  if (!(this instanceof Multipart)) return new Multipart(boy, cfg);\n  var i,\n      len,\n      self = this,\n      boundary,\n      limits = cfg.limits,\n      parsedConType = cfg.parsedConType || [],\n      defCharset = cfg.defCharset || 'utf8',\n      preservePath = cfg.preservePath,\n      fileopts = typeof cfg.fileHwm === 'number' ? {\n    highWaterMark: cfg.fileHwm\n  } : {};\n\n  for (i = 0, len = parsedConType.length; i < len; ++i) {\n    if (Array.isArray(parsedConType[i]) && RE_BOUNDARY.test(parsedConType[i][0])) {\n      boundary = parsedConType[i][1];\n      break;\n    }\n  }\n\n  function checkFinished() {\n    if (nends === 0 && finished && !boy._done) {\n      finished = false;\n      process.nextTick(function () {\n        boy._done = true;\n        boy.emit('finish');\n      });\n    }\n  }\n\n  if (typeof boundary !== 'string') throw new Error('Multipart: Boundary not found');\n  var fieldSizeLimit = limits && typeof limits.fieldSize === 'number' ? limits.fieldSize : 1 * 1024 * 1024,\n      fileSizeLimit = limits && typeof limits.fileSize === 'number' ? limits.fileSize : Infinity,\n      filesLimit = limits && typeof limits.files === 'number' ? limits.files : Infinity,\n      fieldsLimit = limits && typeof limits.fields === 'number' ? limits.fields : Infinity,\n      partsLimit = limits && typeof limits.parts === 'number' ? limits.parts : Infinity;\n  var nfiles = 0,\n      nfields = 0,\n      nends = 0,\n      curFile,\n      curField,\n      finished = false;\n  this._needDrain = false;\n  this._pause = false;\n  this._cb = undefined;\n  this._nparts = 0;\n  this._boy = boy;\n  var parserCfg = {\n    boundary: boundary,\n    maxHeaderPairs: limits && limits.headerPairs\n  };\n  if (fileopts.highWaterMark) parserCfg.partHwm = fileopts.highWaterMark;\n  if (cfg.highWaterMark) parserCfg.highWaterMark = cfg.highWaterMark;\n  this.parser = new Dicer(parserCfg);\n  this.parser.on('drain', function () {\n    self._needDrain = false;\n\n    if (self._cb && !self._pause) {\n      var cb = self._cb;\n      self._cb = undefined;\n      cb();\n    }\n  }).on('part', function onPart(part) {\n    if (++self._nparts > partsLimit) {\n      self.parser.removeListener('part', onPart);\n      self.parser.on('part', skipPart);\n      boy.hitPartsLimit = true;\n      boy.emit('partsLimit');\n      return skipPart(part);\n    } // hack because streams2 _always_ doesn't emit 'end' until nextTick, so let\n    // us emit 'end' early since we know the part has ended if we are already\n    // seeing the next part\n\n\n    if (curField) {\n      var field = curField;\n      field.emit('end');\n      field.removeAllListeners('end');\n    }\n\n    part.on('header', function (header) {\n      var contype,\n          fieldname,\n          parsed,\n          charset,\n          encoding,\n          filename,\n          nsize = 0;\n\n      if (header['content-type']) {\n        parsed = parseParams(header['content-type'][0]);\n\n        if (parsed[0]) {\n          contype = parsed[0].toLowerCase();\n\n          for (i = 0, len = parsed.length; i < len; ++i) {\n            if (RE_CHARSET.test(parsed[i][0])) {\n              charset = parsed[i][1].toLowerCase();\n              break;\n            }\n          }\n        }\n      }\n\n      if (contype === undefined) contype = 'text/plain';\n      if (charset === undefined) charset = defCharset;\n\n      if (header['content-disposition']) {\n        parsed = parseParams(header['content-disposition'][0]);\n        if (!RE_FIELD.test(parsed[0])) return skipPart(part);\n\n        for (i = 0, len = parsed.length; i < len; ++i) {\n          if (RE_NAME.test(parsed[i][0])) {\n            fieldname = decodeText(parsed[i][1], 'binary', 'utf8');\n          } else if (RE_FILENAME.test(parsed[i][0])) {\n            filename = decodeText(parsed[i][1], 'binary', 'utf8');\n            if (!preservePath) filename = basename(filename);\n          }\n        }\n      } else return skipPart(part);\n\n      if (header['content-transfer-encoding']) encoding = header['content-transfer-encoding'][0].toLowerCase();else encoding = '7bit';\n      var onData, onEnd;\n\n      if (contype === 'application/octet-stream' || filename !== undefined) {\n        // file/binary field\n        if (nfiles === filesLimit) {\n          if (!boy.hitFilesLimit) {\n            boy.hitFilesLimit = true;\n            boy.emit('filesLimit');\n          }\n\n          return skipPart(part);\n        }\n\n        ++nfiles;\n\n        if (!boy._events.file) {\n          self.parser._ignore();\n\n          return;\n        }\n\n        ++nends;\n        var file = new FileStream(fileopts);\n        curFile = file;\n        file.on('end', function () {\n          --nends;\n          checkFinished();\n\n          if (self._cb && !self._needDrain) {\n            var cb = self._cb;\n            self._cb = undefined;\n            cb();\n          }\n        });\n\n        file._read = function (n) {\n          if (!self._pause) return;\n          self._pause = false;\n\n          if (self._cb && !self._needDrain) {\n            var cb = self._cb;\n            self._cb = undefined;\n            cb();\n          }\n        };\n\n        boy.emit('file', fieldname, file, filename, encoding, contype);\n\n        onData = function onData(data) {\n          if ((nsize += data.length) > fileSizeLimit) {\n            var extralen = fileSizeLimit - (nsize - data.length);\n            if (extralen > 0) file.push(data.slice(0, extralen));\n            file.emit('limit');\n            file.truncated = true;\n            part.removeAllListeners('data');\n          } else if (!file.push(data)) self._pause = true;\n        };\n\n        onEnd = function onEnd() {\n          curFile = undefined;\n          file.push(null);\n        };\n      } else {\n        // non-file field\n        if (nfields === fieldsLimit) {\n          if (!boy.hitFieldsLimit) {\n            boy.hitFieldsLimit = true;\n            boy.emit('fieldsLimit');\n          }\n\n          return skipPart(part);\n        }\n\n        ++nfields;\n        ++nends;\n        var buffer = '',\n            truncated = false;\n        curField = part;\n\n        onData = function onData(data) {\n          if ((nsize += data.length) > fieldSizeLimit) {\n            var extralen = fieldSizeLimit - (nsize - data.length);\n            buffer += data.toString('binary', 0, extralen);\n            truncated = true;\n            part.removeAllListeners('data');\n          } else buffer += data.toString('binary');\n        };\n\n        onEnd = function onEnd() {\n          curField = undefined;\n          if (buffer.length) buffer = decodeText(buffer, 'binary', charset);\n          boy.emit('field', fieldname, buffer, false, truncated, encoding, contype);\n          --nends;\n          checkFinished();\n        };\n      }\n      /* As of node@2efe4ab761666 (v0.10.29+/v0.11.14+), busboy had become\n         broken. Streams2/streams3 is a huge black box of confusion, but\n         somehow overriding the sync state seems to fix things again (and still\n         seems to work for previous node versions).\n      */\n\n\n      part._readableState.sync = false;\n      part.on('data', onData);\n      part.on('end', onEnd);\n    }).on('error', function (err) {\n      if (curFile) curFile.emit('error', err);\n    });\n  }).on('error', function (err) {\n    boy.emit('error', err);\n  }).on('finish', function () {\n    finished = true;\n    checkFinished();\n  });\n}\n\nMultipart.prototype.write = function (chunk, cb) {\n  var r;\n  if ((r = this.parser.write(chunk)) && !this._pause) cb();else {\n    this._needDrain = !r;\n    this._cb = cb;\n  }\n};\n\nMultipart.prototype.end = function () {\n  var self = this;\n\n  if (this._nparts === 0 && !self._boy._done) {\n    process.nextTick(function () {\n      self._boy._done = true;\n\n      self._boy.emit('finish');\n    });\n  } else if (this.parser.writable) this.parser.end();\n};\n\nfunction skipPart(part) {\n  part.resume();\n}\n\nfunction FileStream(opts) {\n  if (!(this instanceof FileStream)) return new FileStream(opts);\n  ReadableStream.call(this, opts);\n  this.truncated = false;\n}\n\ninherits(FileStream, ReadableStream);\n\nFileStream.prototype._read = function (n) {};\n\nmodule.exports = Multipart;","map":null,"metadata":{},"sourceType":"script"}